import ollama  # è¼‰å…¥ ollama æ¨¡çµ„ï¼Œèˆ‡ Llama AI é€²è¡Œäº’å‹•
import prompt  # è¼‰å…¥ prompt æ¨¡çµ„ï¼Œç”¨ä¾†å„²å­˜æ•™å­¸æŒ‡å¼•ã€æ¸¬é©—å•é¡Œç­‰å…§å®¹

def chat_with_llama():
    # ç”¨ä¾†å„²å­˜å°è©±æ­·å²ï¼Œä»¥ä¾¿ä¿æŒä¸Šä¸‹æ–‡
    messages = []  
    
    # åŠ å…¥åˆå§‹çš„å°è©±è¨Šæ¯ï¼ŒåŒ…å«æŒ‡å¼•ã€æ¸¬é©—å•é¡Œã€é€²åº¦ç­‰
    messages.append({"role": "user", "content": prompt.tutor_guideline})
    messages.append({"role": "user", "content": prompt.teaching_quiz})
    messages.append({"role": "user", "content": prompt.Progress})
    
    # è®€å–ä¹‹å‰å„²å­˜çš„å°è©±æ­·å²ï¼Œä¸¦åŠ å…¥åˆ° messages æ¸…å–®ä¸­
    with open("C:\Python\llama-tutor-agent\message_history.txt", "r", encoding="utf-8") as file:
        history = file.read()  # è®€å–æª”æ¡ˆå…§å®¹
        
    messages.append({"role": "user", "content": "ä»¥ä¸‹ç‚ºæˆ‘å€‘çš„å°è©±ç´€éŒ„,è®€å–ä¸¦ç¹¼çºŒå°è©±"+history})  # æŠŠè®€å–çš„æ­·å²å°è©±åŠ å…¥

    while True:  # æŒçºŒé€²è¡Œå°è©±ï¼Œç›´åˆ°ä½¿ç”¨è€…çµæŸ
        try:
            # æ¥æ”¶ä½¿ç”¨è€…çš„è¼¸å…¥
            user_input = input("ğŸ‘¤ ä½ : ")

            if not (user_input):
                print("ä½ æ²’æœ‰è¼¸å…¥ä»»ä½•å…§å®¹")
                continue ;
            
            # è‹¥ä½¿ç”¨è€…è¼¸å…¥ 'exit'ï¼Œå‰‡çµæŸå°è©±
            if user_input.lower() == "exit":
                print("ğŸ”´ çµæŸå°è©±...\n")
                break  # è·³å‡ºå¾ªç’°çµæŸå°è©±
            
            print("ğŸ¤– Llama: ")
            
            # å„²å­˜ä½¿ç”¨è€…çš„è¼¸å…¥ï¼Œä¸¦åŠ å…¥åˆ°å°è©±æ­·å²
            messages.append({"role": "user", "content": user_input})
            
            # å‘ Llama 3.1 æ¨¡å‹ç™¼é€è«‹æ±‚ï¼Œä¸¦å‚³é€å°è©±æ­·å²
            response = ollama.chat(model='llama3.1:latest', messages=messages)
            
            # å–å¾— AI çš„å›æ‡‰å…§å®¹ï¼Œè‹¥æ²’æœ‰å›æ‡‰å‰‡é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
            bot_reply = response.get('message', {}).get('content', 'âš ï¸ ç„¡æ³•ç²å–å›æ‡‰')
            
            # æŠŠ AI çš„å›æ‡‰åŠ å…¥åˆ°å°è©±æ­·å²ä¸­
            messages.append({"role": "assistant", "content": bot_reply})
            
            # é¡¯ç¤º AI çš„å›æ‡‰
            print(bot_reply)  

        except Exception as e:
            # æ•æ‰ä¸¦é¡¯ç¤ºéŒ¯èª¤è¨Šæ¯
            print(f"âš ï¸ ç™¼ç”ŸéŒ¯èª¤: {e}\n")

# ä¸»ç¨‹å¼ï¼ŒåŸ·è¡Œèˆ‡ Llama çš„å°è©±
if __name__ == "__main__":
    chat_with_llama()  # å‘¼å«å°è©±å‡½å¼
